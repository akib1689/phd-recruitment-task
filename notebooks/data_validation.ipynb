{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Data Validation & CFG Pair Inspection\n",
    "\n",
    "Validates the CSV dataset generated from Boa (`job-*.csv`), checks:\n",
    "- PRE/POST balance\n",
    "- CFG parseability (DOT format)\n",
    "- Sample method-level pairing\n",
    "\n",
    "Based on data in `../assets/data-samples/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from IPython.display import display, SVG\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=pd.errors.ParserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Ensure the `utils` module is on the Python path\n",
    "sys.path.insert(0, os.path.abspath('utils'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../assets/data-samples/\"\n",
    "csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "print(f\"Found {len(csv_files)} CSV files:\")\n",
    "for f in sorted(csv_files):\n",
    "    size_mb = os.path.getsize(os.path.join(data_dir, f)) / (1024**2)\n",
    "    print(f\"  - {f} ({size_mb:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load smallest sample (or prompt for job ID)\n",
    "if csv_files:\n",
    "    sample_file = min(csv_files, key=lambda f: os.path.getsize(os.path.join(data_dir, f)))\n",
    "    df = pd.read_csv(os.path.join(data_dir, sample_file))\n",
    "    print(f\"✓ Loaded {len(df)} rows from {sample_file}\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"No CSV files found in assets/data-samples/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic info\n",
    "\n",
    "print(\"\\n=== Data Information ===\")\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# Remove effectively empty columns\n",
    "from utils.is_column_empty import is_effectively_empty\n",
    "\n",
    "cols_to_drop = [col for col in df.columns if is_effectively_empty(df[col])]\n",
    "\n",
    "if cols_to_drop:\n",
    "    print(f\"Removing effectively empty columns: {cols_to_drop}\")\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "\n",
    "# Check for malformed cfg_state\n",
    "\n",
    "invalid_states = df[~df['cfg_state'].isin(['PRE', 'POST'])]\n",
    "\n",
    "if len(invalid_states) > 0:\n",
    "\n",
    "    print(f\"{len(invalid_states)} rows with invalid cfg_state (e.g. blank/NaN)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate PRE/POST pairing\n",
    "def is_interesting_method(name: str) -> bool:\n",
    "    # Exclude constructors, getters, trivial methods\n",
    "    return (\n",
    "        name not in {'<init>', '<clinit>'} \n",
    "        and not name.startswith('get') \n",
    "        and not name.startswith('set')\n",
    "        and not name.startswith('is')   # e.g., isEmpty()\n",
    "        and len(name) > 3  # skip super-short names like \"run\", \"do\"\n",
    "        and not re.match(r'^[_a-z]+$', name)  # prefer camelCase (common in Java methods)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply filter to df before pairing analysis\n",
    "df_interesting = df[df['method_name'].apply(is_interesting_method)].copy()\n",
    "\n",
    "# Now recompute pairing on filtered data\n",
    "pair_key = ['commit_url', 'file_path', 'method_name']\n",
    "grouped = df_interesting.groupby(pair_key)['cfg_state'].apply(set).reset_index()\n",
    "grouped['has_pair'] = grouped['cfg_state'].apply(lambda s: s == {'PRE', 'POST'})\n",
    "\n",
    "paired_count = grouped['has_pair'].sum()\n",
    "total_groups = len(grouped)\n",
    "print(f\"=== Pairing Integrity (Interesting Methods Only) ===\")\n",
    "print(f\"- {paired_count:,} / {total_groups:,} method-commit groups have both PRE & POST\")\n",
    "print(f\"- Pairing rate: {100 * paired_count / total_groups:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydot\n",
    "\n",
    "# Optional: progress bar (install with `pip install tqdm`)\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# --- 1. Define robust node/edge counter ---\n",
    "def count_nodes_edges(dot_str):\n",
    "    if pd.isna(dot_str) or not isinstance(dot_str, str) or not dot_str.strip():\n",
    "        return pd.Series([np.nan, np.nan], index=['node_count', 'edge_count'])\n",
    "    \n",
    "    # Safety: skip extremely large DOTs (likely malformed or pathological)\n",
    "    if len(dot_str) > 200_000:  # >200 KB → unlikely for real CFGs\n",
    "        return pd.Series([np.nan, np.nan], index=['node_count', 'edge_count'])\n",
    "\n",
    "    try:\n",
    "        # Ensure valid digraph syntax\n",
    "        if 'digraph' not in dot_str:\n",
    "            dot_str = f'digraph G {{\\n{dot_str}\\n}}'\n",
    "        \n",
    "        graphs = pydot.graph_from_dot_data(dot_str)\n",
    "        if not graphs:\n",
    "            return pd.Series([np.nan, np.nan], index=['node_count', 'edge_count'])\n",
    "        g = graphs[0]\n",
    "\n",
    "        # Filter out meta-nodes like 'node' and 'edge' (default attribute blocks)\n",
    "        real_nodes = [\n",
    "            n for n in g.get_nodes()\n",
    "            if n.get_name() and n.get_name().strip('\"') not in {'node', 'edge', ''}\n",
    "        ]\n",
    "        node_count = len(real_nodes)\n",
    "        edge_count = len(g.get_edges())\n",
    "\n",
    "        return pd.Series([node_count, edge_count], index=['node_count', 'edge_count'])\n",
    "\n",
    "    except Exception as e:\n",
    "        # Optional: log or collect errors separately\n",
    "        # print(f\"Parse error: {type(e).__name__}: {str(e)[:80]}\")\n",
    "        return pd.Series([np.nan, np.nan], index=['node_count', 'edge_count'])\n",
    "\n",
    "# --- 2. Create new analysis DataFrame ---\n",
    "# Select only rows with non-null, non-empty cfg_dot\n",
    "cfg_df = df[df['cfg_dot'].notna() & df['cfg_dot'].astype(str).str.strip().astype(bool)].copy()\n",
    "\n",
    "print(f\"Starting with {len(cfg_df)} rows with non-empty cfg_dot (out of {len(df)})\")\n",
    "\n",
    "# --- 3. Compute metrics ---\n",
    "print(\"Parsing CFGs and counting nodes/edges...\")\n",
    "metrics = cfg_df['cfg_dot'].progress_apply(count_nodes_edges)  # or .apply() without tqdm\n",
    "cfg_df = pd.concat([cfg_df.reset_index(drop=True), metrics.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# --- 4. Drop rows where parsing failed (NaN counts) ---\n",
    "initial_len = len(cfg_df)\n",
    "cfg_df = cfg_df.dropna(subset=['node_count', 'edge_count'])\n",
    "cfg_df[['node_count', 'edge_count']] = cfg_df[['node_count', 'edge_count']].astype(int)\n",
    "\n",
    "print(f\"Parsed successfully: {len(cfg_df)} CFGs ({len(cfg_df)/initial_len:.1%} success rate)\")\n",
    "\n",
    "# Optional: Add derived metrics\n",
    "cfg_df['avg_edges_per_node'] = (cfg_df['edge_count'] / cfg_df['node_count']).round(2)\n",
    "cfg_df['is_cyclic'] = cfg_df['edge_count'] >= cfg_df['node_count']  # naive proxy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if paired_count > 0:\n",
    "    # Find first pair *with structural change* (Δ nodes or edges ≠ 0)\n",
    "    # First, compute metrics on df_interesting\n",
    "    df_interesting[['node_count', 'edge_count']] = df_interesting['cfg_dot'].apply(\n",
    "        lambda x: pd.Series(count_nodes_edges(x))\n",
    "    )\n",
    "    \n",
    "    # Merge metrics back & find changed pairs\n",
    "    pair_subset = grouped[grouped['has_pair']][pair_key].drop(\n",
    "        columns=['node_count', 'edge_count'], errors='ignore'\n",
    "    )\n",
    "    merged = df_interesting.merge(pair_subset, on=pair_key, how='inner')\n",
    "    \n",
    "    # Group by method and check for Δ\n",
    "    def has_change(group):\n",
    "        # Expect at most 2 rows: PRE and POST\n",
    "        if len(group) < 2:\n",
    "            return False\n",
    "        pre_row = group[group['cfg_state'] == 'PRE']\n",
    "        post_row = group[group['cfg_state'] == 'POST']\n",
    "        if pre_row.empty or post_row.empty:\n",
    "            return False\n",
    "        pre_n, pre_e = pre_row.iloc[0]['node_count'], pre_row.iloc[0]['edge_count']\n",
    "        post_n, post_e = post_row.iloc[0]['node_count'], post_row.iloc[0]['edge_count']\n",
    "        return (pre_n != post_n) or (pre_e != post_e)\n",
    "\n",
    "    # Changed pairs\n",
    "    changed_pairs = merged.groupby(pair_key).filter(has_change)\n",
    "    \n",
    "    if len(changed_pairs) > 0:\n",
    "        # Pick first *changed* pair\n",
    "        first_changed = changed_pairs.iloc[0]\n",
    "        sample_pair = df_interesting[\n",
    "            (df_interesting['commit_url'] == first_changed['commit_url']) &\n",
    "            (df_interesting['file_path'] == first_changed['file_path']) &\n",
    "            (df_interesting['method_name'] == first_changed['method_name'])\n",
    "        ][['commit_url', 'file_path', 'method_name', 'cfg_state', 'cfg_dot', 'node_count', 'edge_count']]\n",
    "        print(\"--- Sample CHANGED Pair (Structural Diff Detected) ---\")\n",
    "    else:\n",
    "        # Fallback: just pick first interesting pair\n",
    "        first_paired = grouped[grouped['has_pair']].iloc[0]\n",
    "        sample_pair = df_interesting[\n",
    "            (df_interesting['commit_url'] == first_paired['commit_url']) &\n",
    "            (df_interesting['file_path'] == first_paired['file_path']) &\n",
    "            (df_interesting['method_name'] == first_paired['method_name'])\n",
    "        ][['commit_url', 'file_path', 'method_name', 'cfg_state', 'cfg_dot', 'node_count', 'edge_count']]\n",
    "        print(\"--- Sample Pair (No structural change, but method is interesting) ---\")\n",
    "    \n",
    "    # Print metadata\n",
    "    row0 = sample_pair.iloc[0]\n",
    "    print(f\"Commit URL: {row0['commit_url']}\")\n",
    "    print(f\"File Path: {row0['file_path']}\")\n",
    "    print(f\"Method: {row0['method_name']}\")\n",
    "    print(f\"Node/Edge counts:\\n{sample_pair[['cfg_state','node_count','edge_count']].to_string(index=False)}\")\n",
    "    display(sample_pair[['cfg_state', 'cfg_dot']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Summary Stats ===\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CFG Complexity Summary (by cfg_state)\")\n",
    "print(\"=\"*50)\n",
    "summary = cfg_df.groupby('cfg_state').agg(\n",
    "    count=('node_count', 'size'),\n",
    "    node_mean=('node_count', 'mean'),\n",
    "    node_median=('node_count', 'median'),\n",
    "    node_max=('node_count', 'max'),\n",
    "    edge_mean=('edge_count', 'mean'),\n",
    "    edge_median=('edge_count', 'median'),\n",
    "    edge_max=('edge_count', 'max')\n",
    ").round(1)\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# === Visualizations (requires matplotlib/seaborn) ===\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Nodes\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(data=cfg_df, x='cfg_state', y='node_count', showfliers=False)\n",
    "plt.title('Node Count Distribution (PRE vs POST)')\n",
    "plt.ylabel('Number of Nodes')\n",
    "\n",
    "# Edges\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(data=cfg_df, x='cfg_state', y='edge_count', showfliers=False)\n",
    "plt.title('Edge Count Distribution (PRE vs POST)')\n",
    "plt.ylabel('Number of Edges')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: Scatter (nodes vs edges), colored by state\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.scatterplot(\n",
    "    data=cfg_df[cfg_df['node_count'] <= 200],  # cap for readability\n",
    "    x='node_count', y='edge_count', hue='cfg_state', alpha=0.6, s=20\n",
    ")\n",
    "plt.title('CFG Size: Nodes vs Edges (capped at 200 nodes)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_dot(dot_str):\n",
    "    \"\"\"Replace all node IDs like [123] with [N0], [N1], ... in order of appearance\"\"\"\n",
    "    if not isinstance(dot_str, str):\n",
    "        return \"\"\n",
    "    # Extract all node IDs (e.g., [42], n1, \"entry\") — Boa typically uses [num]\n",
    "    # We'll assume Boa uses [digits] as node IDs (adjust if needed)\n",
    "    nodes = re.findall(r'\\[(\\d+)\\]', dot_str)\n",
    "    uniq_nodes = list(dict.fromkeys(nodes))  # preserve order, dedupe\n",
    "    mapping = {old: f\"N{i}\" for i, old in enumerate(uniq_nodes)}\n",
    "    \n",
    "    # Replace each [old] with [new]\n",
    "    norm = dot_str\n",
    "    for old, new in mapping.items():\n",
    "        norm = re.sub(rf'\\[{old}\\]', f'[{new}]', norm)\n",
    "    \n",
    "    # Also sort edges and clean whitespace for stable comparison\n",
    "    lines = [line.strip() for line in norm.split(';') if line.strip()]\n",
    "    lines.sort()\n",
    "    return '; '.join(lines)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Render DOT as SVG (safe for malformed DOT)\n",
    "def render_cfg(dot_str, title=\"CFG\"):\n",
    "    try:\n",
    "        # Boa’s DOT may have \\l line breaks → replace with \\n for Graphviz\n",
    "        dot_clean = re.sub(r'\\\\l', r'\\\\n', dot_str)\n",
    "        dot_clean = re.sub(r'\\\\n\\s*', r'\\\\n', dot_clean)\n",
    "        \n",
    "        # Ensure graph has a name\n",
    "        if not dot_clean.strip().startswith('digraph'):\n",
    "            dot_clean = 'digraph G {' + dot_clean + '}'\n",
    "        \n",
    "        src = graphviz.Source(dot_clean, format='svg')\n",
    "        svg = src.pipe(format='svg').decode('utf-8')\n",
    "        return SVG(svg)\n",
    "    except Exception as e:\n",
    "        return f\"Failed to render CFG: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure required imports (add at top of notebook if not already)\n",
    "try:\n",
    "    import graphviz\n",
    "    from IPython.display import SVG, HTML, display\n",
    "except ImportError as e:\n",
    "    raise ImportError(\n",
    "        \"Missing dependencies: pip install graphviz && (system) apt install graphviz\"\n",
    "    ) from e\n",
    "\n",
    "# --- Use the improved render_cfg from previous answer (included here for completeness) ---\n",
    "def render_cfg(dot_str, title=\"CFG\", max_width=\"100%\", max_height=\"400px\"):\n",
    "    if not dot_str or not isinstance(dot_str, str):\n",
    "        return HTML(f\"<div style='color:red;'><b>{title}</b>: Empty or invalid DOT</div>\")\n",
    "\n",
    "    try:\n",
    "        dot_clean = dot_str.strip()\n",
    "        # Fix Boa line breaks\n",
    "        dot_clean = re.sub(r'\\\\l', r'\\\\n', dot_clean)\n",
    "        # Remove inline comments\n",
    "        dot_clean = re.sub(r'//.*', '', dot_clean)\n",
    "        # Wrap in digraph if needed\n",
    "        if not re.match(r'^\\s*(strict\\s+)?digraph', dot_clean, re.I):\n",
    "            dot_clean = f'digraph G {{\\n{dot_clean}\\n}}'\n",
    "        # Escape quotes in labels (minimal fix)\n",
    "        dot_clean = re.sub(r'label=\"([^\"]*)\"', lambda m: f'label=\"{m.group(1).replace('\"', '\\\\\"')}\"', dot_clean)\n",
    "\n",
    "        src = graphviz.Source(dot_clean, format='svg', engine='dot')\n",
    "        svg_data = src.pipe(format='svg')\n",
    "        svg_str = svg_data.decode('utf-8')\n",
    "\n",
    "        style = (\n",
    "            f\"max-width:{max_width}; max-height:{max_height}; \"\n",
    "            \"overflow:auto; border:1px solid #ddd; margin:8px 0; padding:4px;\"\n",
    "        )\n",
    "        return HTML(f'''\n",
    "        <div><b>{title}</b></div>\n",
    "        <div style=\"{style}\">\n",
    "            {svg_str}\n",
    "        </div>\n",
    "        ''')\n",
    "\n",
    "    except Exception as e:\n",
    "        snippet = repr(dot_str[:150])\n",
    "        return HTML(\n",
    "            f\"<div style='color:#d63031;'><b>{title}</b>: Render failed<br>\"\n",
    "            f\"<small><code>{type(e).__name__}: {str(e)[:120]}</code></small><br>\"\n",
    "            f\"<em>Snippet:</em> <code>{snippet}</code></div>\"\n",
    "        )\n",
    "\n",
    "# --- Updated visualization block ---\n",
    "if 'sample_pair' in locals() and len(sample_pair) == 2:\n",
    "    # Extract once, safely\n",
    "    row0 = sample_pair.iloc[0]\n",
    "    commit_url = row0['commit_url']\n",
    "    file_path = row0['file_path']\n",
    "    method_name = row0['method_name']\n",
    "    \n",
    "    print(\"Sample CFG Pair (PRE → POST)\")\n",
    "    print(f\"Commit URL: {commit_url}\")\n",
    "    print(f\"File Path:  {file_path}\")\n",
    "    print(f\"Method:     {method_name}\")\n",
    "    print()\n",
    "    \n",
    "    # Safely extract PRE/POST cfg_dot\n",
    "    pre_row = sample_pair[sample_pair['cfg_state'] == 'PRE']\n",
    "    post_row = sample_pair[sample_pair['cfg_state'] == 'POST']\n",
    "    \n",
    "    if len(pre_row) == 0 or len(post_row) == 0:\n",
    "        print(\"Missing PRE or POST CFG in sample_pair.\")\n",
    "    else:\n",
    "        pre_cfg = pre_row['cfg_dot'].iloc[0]\n",
    "        post_cfg = post_row['cfg_dot'].iloc[0]\n",
    "        \n",
    "        display(render_cfg(pre_cfg, f\"PRE: {method_name}\"))\n",
    "        \n",
    "        display(render_cfg(post_cfg, f\"POST: {method_name}\"))\n",
    "\n",
    "        # Optional: add structural diff hint\n",
    "        if pre_cfg and post_cfg:\n",
    "            pre_norm = normalize_dot(pre_cfg)  # from earlier helper\n",
    "            post_norm = normalize_dot(post_cfg)\n",
    "            if pre_norm == post_norm:\n",
    "                print(\"CFGs are structurally identical (after node ID normalization).\")\n",
    "            else:\n",
    "                print(\"CFGs differ structurally — likely control-flow change in patch.\")\n",
    "else:\n",
    "    print(\"No full PRE/POST pair found in `sample_pair`. Try:\")\n",
    "    print(\"   sample_pair = df[(df['method_name'] == 'YourMethod') & (df['cfg_dot'].notna())]\")\n",
    "    print(\"# Ensure it contains both 'PRE' and 'POST' rows\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Boa Client (Python 3.13)",
   "language": "python",
   "name": "boa-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
